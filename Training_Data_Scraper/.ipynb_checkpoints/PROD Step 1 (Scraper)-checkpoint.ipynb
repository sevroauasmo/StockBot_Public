{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c369edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kodk filing that kicked this whole thing off\n",
    "# https://www.secform4.com/filings/31235/0000891839-20-000226.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717d4c5",
   "metadata": {},
   "source": [
    "# Start with Indexing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f17dee",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameter tagged cell- for use with shell script!\n",
    "year = 2014\n",
    "quarter = 'QTR1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e25c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import edgar\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696497d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2e7c04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ua = [insert your user agent string]\n",
    "\n",
    "edgar.download_index('/Users/rileybitterli/Desktop/StockBot_Data/StockBot_Indices', 2005, ua, skip_all_present_except_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b9171d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "file_path = f'/Users/rileybitterli/Desktop/StockBot_Data/StockBot_Indices/{year}-{quarter}.tsv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd18206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rileybitterli/Desktop/StockBot_Data/StockBot_Indices/2014-QTR1.tsv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73c6e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.read_csv(file_path, delimiter= '|', names = ('CIK', 'Name', 'Form_Type', 'Date', 'URL_TXT', 'URL_HTML'))\n",
    "\n",
    "index_df = index_df[index_df['Form_Type']=='4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2208bf42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_df['FileURL'] = 'https://sec.gov/Archives/' + index_df['URL_HTML']\n",
    "index_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf71a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_df['Date'] = pd.to_datetime(index_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4742a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Name</th>\n",
       "      <th>Form_Type</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL_TXT</th>\n",
       "      <th>URL_HTML</th>\n",
       "      <th>FileURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000032</td>\n",
       "      <td>BINCH JAMES G</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-03-03</td>\n",
       "      <td>edgar/data/1000032/0001181431-14-010250.txt</td>\n",
       "      <td>edgar/data/1000032/0001181431-14-010250-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/1000032/0001181431-14-010250-index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1000180</td>\n",
       "      <td>SANDISK CORP</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>edgar/data/1000180/0001242648-14-000001.txt</td>\n",
       "      <td>edgar/data/1000180/0001242648-14-000001-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/1000180/0001242648-14-000001-index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1000180</td>\n",
       "      <td>SANDISK CORP</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>edgar/data/1000180/0001242648-14-000002.txt</td>\n",
       "      <td>edgar/data/1000180/0001242648-14-000002-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/1000180/0001242648-14-000002-index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1000180</td>\n",
       "      <td>SANDISK CORP</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>edgar/data/1000180/0001242648-14-000003.txt</td>\n",
       "      <td>edgar/data/1000180/0001242648-14-000003-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/1000180/0001242648-14-000003-index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>1000180</td>\n",
       "      <td>SANDISK CORP</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>edgar/data/1000180/0001242648-14-000004.txt</td>\n",
       "      <td>edgar/data/1000180/0001242648-14-000004-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/1000180/0001242648-14-000004-index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128962</th>\n",
       "      <td>311687</td>\n",
       "      <td>9984</td>\n",
       "      <td>BARNES GROUP INC</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000033.txt</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000033-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/9984/0000009984-14-000033-index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128963</th>\n",
       "      <td>311688</td>\n",
       "      <td>9984</td>\n",
       "      <td>BARNES GROUP INC</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000034.txt</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000034-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/9984/0000009984-14-000034-index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128964</th>\n",
       "      <td>311689</td>\n",
       "      <td>9984</td>\n",
       "      <td>BARNES GROUP INC</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000035.txt</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000035-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/9984/0000009984-14-000035-index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128965</th>\n",
       "      <td>311690</td>\n",
       "      <td>9984</td>\n",
       "      <td>BARNES GROUP INC</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-03-11</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000036.txt</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000036-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/9984/0000009984-14-000036-index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128966</th>\n",
       "      <td>311691</td>\n",
       "      <td>9984</td>\n",
       "      <td>BARNES GROUP INC</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-03-11</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000037.txt</td>\n",
       "      <td>edgar/data/9984/0000009984-14-000037-index.html</td>\n",
       "      <td>https://sec.gov/Archives/edgar/data/9984/0000009984-14-000037-index.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128967 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index      CIK              Name Form_Type       Date  \\\n",
       "0            0  1000032     BINCH JAMES G         4 2014-03-03   \n",
       "1           17  1000180      SANDISK CORP         4 2014-01-08   \n",
       "2           18  1000180      SANDISK CORP         4 2014-01-10   \n",
       "3           19  1000180      SANDISK CORP         4 2014-01-29   \n",
       "4           20  1000180      SANDISK CORP         4 2014-01-31   \n",
       "...        ...      ...               ...       ...        ...   \n",
       "128962  311687     9984  BARNES GROUP INC         4 2014-02-27   \n",
       "128963  311688     9984  BARNES GROUP INC         4 2014-02-28   \n",
       "128964  311689     9984  BARNES GROUP INC         4 2014-02-28   \n",
       "128965  311690     9984  BARNES GROUP INC         4 2014-03-11   \n",
       "128966  311691     9984  BARNES GROUP INC         4 2014-03-11   \n",
       "\n",
       "                                            URL_TXT  \\\n",
       "0       edgar/data/1000032/0001181431-14-010250.txt   \n",
       "1       edgar/data/1000180/0001242648-14-000001.txt   \n",
       "2       edgar/data/1000180/0001242648-14-000002.txt   \n",
       "3       edgar/data/1000180/0001242648-14-000003.txt   \n",
       "4       edgar/data/1000180/0001242648-14-000004.txt   \n",
       "...                                             ...   \n",
       "128962     edgar/data/9984/0000009984-14-000033.txt   \n",
       "128963     edgar/data/9984/0000009984-14-000034.txt   \n",
       "128964     edgar/data/9984/0000009984-14-000035.txt   \n",
       "128965     edgar/data/9984/0000009984-14-000036.txt   \n",
       "128966     edgar/data/9984/0000009984-14-000037.txt   \n",
       "\n",
       "                                                  URL_HTML  \\\n",
       "0       edgar/data/1000032/0001181431-14-010250-index.html   \n",
       "1       edgar/data/1000180/0001242648-14-000001-index.html   \n",
       "2       edgar/data/1000180/0001242648-14-000002-index.html   \n",
       "3       edgar/data/1000180/0001242648-14-000003-index.html   \n",
       "4       edgar/data/1000180/0001242648-14-000004-index.html   \n",
       "...                                                    ...   \n",
       "128962     edgar/data/9984/0000009984-14-000033-index.html   \n",
       "128963     edgar/data/9984/0000009984-14-000034-index.html   \n",
       "128964     edgar/data/9984/0000009984-14-000035-index.html   \n",
       "128965     edgar/data/9984/0000009984-14-000036-index.html   \n",
       "128966     edgar/data/9984/0000009984-14-000037-index.html   \n",
       "\n",
       "                                                                            FileURL  \n",
       "0       https://sec.gov/Archives/edgar/data/1000032/0001181431-14-010250-index.html  \n",
       "1       https://sec.gov/Archives/edgar/data/1000180/0001242648-14-000001-index.html  \n",
       "2       https://sec.gov/Archives/edgar/data/1000180/0001242648-14-000002-index.html  \n",
       "3       https://sec.gov/Archives/edgar/data/1000180/0001242648-14-000003-index.html  \n",
       "4       https://sec.gov/Archives/edgar/data/1000180/0001242648-14-000004-index.html  \n",
       "...                                                                             ...  \n",
       "128962     https://sec.gov/Archives/edgar/data/9984/0000009984-14-000033-index.html  \n",
       "128963     https://sec.gov/Archives/edgar/data/9984/0000009984-14-000034-index.html  \n",
       "128964     https://sec.gov/Archives/edgar/data/9984/0000009984-14-000035-index.html  \n",
       "128965     https://sec.gov/Archives/edgar/data/9984/0000009984-14-000036-index.html  \n",
       "128966     https://sec.gov/Archives/edgar/data/9984/0000009984-14-000037-index.html  \n",
       "\n",
       "[128967 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdaf48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_500 = index_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203ba85",
   "metadata": {},
   "source": [
    "# Scraping/Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9ecc460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import concurrent.futures\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup \n",
    "from random import uniform\n",
    "from time import sleep\n",
    "import lxml\n",
    "from bs4.formatter import HTMLFormatter\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "import threading\n",
    "from multiprocessing import Pool\n",
    "import more_itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26ec3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(subject, content):\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(content)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = 'halpitsstockbot@gmail.com'\n",
    "    msg['To'] = 'riley.bitterli@gmail.com'\n",
    "\n",
    "    # Establish a connection to Gmail\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.starttls()\n",
    "    server.login([insert your email address], [inser your password])\n",
    "    server.send_message(msg)\n",
    "    server.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64a179e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get selenium all defined and set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e383e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_path = ChromeDriverManager().install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496063ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"THIRD_PARTY_NOTICES.chromedriver\" in chrome_path:\n",
    "    chrome_path = chrome_path.replace(\"THIRD_PARTY_NOTICES.chromedriver\", \"chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b13cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Service(chrome_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d60092",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-background-timer-throttling\")\n",
    "chrome_options.add_argument(\"--disable-backgrounding-occluded-windows\")\n",
    "chrome_options.add_argument(\"--disable-renderer-backgrounding\")\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")  \n",
    "chrome_options.add_argument(\"--enable-accelerated-2d-canvas\")\n",
    "chrome_options.add_argument(\"--ignore-gpu-blacklist\")\n",
    "chrome_options.add_argument(\"--no-sandbox\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f786b9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.options.Options at 0x7f9840155fd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrome_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6284832c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128967"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_500) #not actually first 500- keep around as a variable name out of nostalgia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a049e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = f\"/Users/rileybitterli/Desktop/StockBot_Data/Draft_VIII/Pickle_Files/{year}/{quarter}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a9e828f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest batch number found: 32\n"
     ]
    }
   ],
   "source": [
    "#only necessary if you've already run for a bit on a particular quarter\n",
    "import os\n",
    "import re\n",
    "\n",
    "def find_highest_batch_number(directory_path):\n",
    "    # check if the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory {directory_path} does not exist.\")\n",
    "        return 0\n",
    "\n",
    "    max_batch_number = -1  # initialize the maximum batch number as -1 to indicate not found\n",
    "\n",
    "    # loop through each file in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.pkl'):\n",
    "            # extract the batch number from the filename using regex\n",
    "            match = re.search(r\"batch(\\d+)\", filename)\n",
    "            if match:\n",
    "                batch_number = int(match.group(1))\n",
    "                max_batch_number = max(max_batch_number, batch_number)\n",
    "\n",
    "    if max_batch_number == -1:\n",
    "        print(\"No batch number found in any file.\")\n",
    "        return 0\n",
    "    else:\n",
    "        print(f\"Highest batch number found: {max_batch_number}\")\n",
    "        return max_batch_number\n",
    "\n",
    "highest_batch = find_highest_batch_number(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6842fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_batch = [highest_batch if highest_batch is not None and highest_batch > 0 else 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1142e292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "highest_batch = int(highest_batch[0]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3c264f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08bbfed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert DataFrame columns into a list of tuples\n",
    "url_date_pairs = list(zip(first_500['FileURL'], first_500['Date']))\n",
    "\n",
    "# define the chunk size\n",
    "chunk_size = 1000\n",
    "\n",
    "# create chunks\n",
    "chunks = list(enumerate([url_date_pairs[i:i + chunk_size] for i in range(0, len(url_date_pairs), chunk_size)]))\n",
    "\n",
    "# now, `chunks` is a list of indexed tuples, where each tuple contains an index and a list of up to 100 URL-Date pairings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1cd71c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def filter_chunks(directory_path, chunks):\n",
    "    found_batches = []\n",
    "    \n",
    "    # check if the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory {directory_path} does not exist.\")\n",
    "        return chunks\n",
    "    \n",
    "    # loop through each file in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.pkl'):\n",
    "            # extract the batch number from the filename using regex\n",
    "            match = re.search(r\"batch(\\d+)\", filename)\n",
    "            if match:\n",
    "                # append the found batch number to the list\n",
    "                batch_number = int(match.group(1))\n",
    "                found_batches.append(batch_number)\n",
    "    \n",
    "    # remove the elements in chunks that correspond to the found batch numbers\n",
    "    filtered_chunks = [chunk for i, chunk in enumerate(chunks) if i not in found_batches]\n",
    "    \n",
    "    return filtered_chunks\n",
    "\n",
    "\n",
    "\n",
    "result_chunks = filter_chunks(directory_path, chunks)\n",
    "print(result_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d805eaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fad5803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8ed3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date: 2024-06-13\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# get the current date\n",
    "current_date = datetime.now().date()\n",
    "\n",
    "print(\"Current date:\", current_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f222da10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory path already exists: /Users/rileybitterli/Desktop/StockBot_Data/Draft_VIII/Pickle_Files/2014/QTR1\n"
     ]
    }
   ],
   "source": [
    "#make sure directory path exists\n",
    "import os\n",
    "\n",
    "def ensure_directory_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Made directory path: {path}\")\n",
    "    else:\n",
    "        print(f\"Directory path already exists: {path}\")\n",
    "\n",
    "# usage before saving the file\n",
    "directory_path = f\"/Users/rileybitterli/Desktop/StockBot_Data/Draft_VIII/Pickle_Files/{year}/{quarter}\"\n",
    "ensure_directory_exists(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c940cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    " send_email('its me', 'starting scraping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22459a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavy lifter of those notebook- open up each of the links, navigate it, rip what we need, store in pickle file every 1000\n",
    "\n",
    "import threading\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "from random import uniform\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "# for thread safety\n",
    "batch_number_counter = [highest_batch]  # use a list so it's mutable\n",
    "batch_number_lock = threading.Lock()\n",
    "\n",
    "def scrape_chunk(chunk_number, chunk):\n",
    "    global batch_number_counter\n",
    "    necessary_dfs = []  \n",
    "    # setup a new webdriver instance\n",
    "    driver = webdriver.Chrome(service=s, options = chrome_options)\n",
    "    driver.delete_all_cookies()\n",
    "    index = 0\n",
    "    url_counter = 0\n",
    "    with batch_number_lock:\n",
    "        batch_number = batch_number_counter[0]\n",
    "        batch_number_counter[0] += 1\n",
    "\n",
    "    for url, date in chunk:\n",
    "        index += 1\n",
    "        try: \n",
    "            sec = uniform(.4,1)\n",
    "            print(\"I slept for:\", round(sec, 2), \"seconds, and my index is:\", index, \"url counter is:\", url_counter, 'batch number', batch_number, \"chunk_number:\", chunk_number)\n",
    "            driver.get(url)\n",
    "            sleep(sec)\n",
    "            web_elements = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "            links = [we.get_attribute(\"href\") for we in web_elements if we.get_attribute(\"href\")]\n",
    "            html_links = [link for link in links if 'xml' in link]\n",
    "    \n",
    "            if html_links:\n",
    "                driver.get(html_links[0])\n",
    "                full_page = driver.page_source.replace('%', '')\n",
    "                dfs = pd.read_html(full_page)\n",
    "\n",
    "        \n",
    "                for df in dfs:\n",
    "                   if isinstance(df, pd.DataFrame):\n",
    "                    try:\n",
    "                        # ensure we're working with a string for the regex search\n",
    "                        first_item = str(df.iloc[0, 1]) if not df.empty and df.columns.size > 1 else \"\"\n",
    "                        bracket_match = re.search(r'\\[(.*?)\\]', first_item)\n",
    "                        if bracket_match:\n",
    "                            ticker = bracket_match.group(1)  # Extract the value between the brackets\n",
    "                            name = df.iloc[1, 1]\n",
    "                    except Exception as e:\n",
    "                        # if any error occurs, ignore and move on\n",
    "                        pass \n",
    "\n",
    "                    if isinstance(df.columns, pd.MultiIndex):\n",
    "                        for col in df.columns.levels[0]:\n",
    "                            if col.startswith('Table I - Non-Derivative Securities Acquired, Disposed of, or Beneficially Owned'):\n",
    "                                df.columns = df.columns.droplevel(0).droplevel(0)\n",
    "                                df.rename(columns={\n",
    "                                        '1. Title of Security (Instr. 3)': 'security_type',\n",
    "                                        '2. Transaction Date  (Month/Day/Year)': 'date',\n",
    "                                        '2A. Deemed Execution Date, if any  (Month/Day/Year)': 'execution_date',\n",
    "                                        'Code': 'code',\n",
    "                                        'V': 'v',\n",
    "                                        '(A) or (D)': 'a_or_d',\n",
    "                                        'Amount': 'amount',\n",
    "                                        '5. Amount of Securities Beneficially Owned Following Reported Transaction(s) (Instr. 3 and 4)': 'total_owned_after_trans',\n",
    "                                        '6. Ownership Form: Direct (D) or Indirect (I) (Instr. 4)': 'direct_or_indirect'\n",
    "                                    }, inplace=True)\n",
    "\n",
    "                                df['URL'] = url\n",
    "                                df['Filing Date'] = date\n",
    "                                df['Ticker'] = ticker\n",
    "                                df['Name'] = name\n",
    "\n",
    "                                if 'code' in df.columns and (df['code'].eq('P').any() or df['code'].eq('S').any()):\n",
    "                                    necessary_dfs.append(df)\n",
    "                                        \n",
    "                                        \n",
    "                                        \n",
    "                url_counter += 1\n",
    "                if url_counter == 1000:\n",
    "                     with open(f\"/Users/rileybitterli/Desktop/StockBot_Data/Draft_VIII/Pickle_Files/{year}/{quarter}/{current_date}_batch{batch_number}.pkl\", \"wb\") as file:\n",
    "                        pickle.dump(necessary_dfs, file)\n",
    "                        necessary_dfs = []\n",
    "                        url_counter = 0\n",
    "                        \n",
    "                        \n",
    "        except IndexError as ie:\n",
    "            print(f\"Skipped URL due to error at index:{index}. Error: {str(ie)}\")\n",
    "            continue\n",
    "                        \n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        except Exception as e:\n",
    "            if \"Document is empty\" in str(e):\n",
    "                print(f\"Skipped URL due to error at index:{index}. Error: {str(e)}\")\n",
    "                continue\n",
    "            else:\n",
    "                send_email('Error in Jupyter Notebook', f\"Broke at index:{index} An error occurred: {str(e)}\")\n",
    "                raise e\n",
    "\n",
    "    if necessary_dfs:\n",
    "        with open(f\"/Users/rileybitterli/Desktop/StockBot_Data/Draft_VIII/Pickle_Files/{year}/{quarter}/{current_date}_batch{batch_number}.pkl\", \"wb\") as file:\n",
    "            pickle.dump(necessary_dfs, file)\n",
    "            necessary_dfs = []\n",
    "            url_counter = 0\n",
    "    print('all done')\n",
    "    driver.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = [executor.submit(scrape_chunk, chunk[0], chunk[1]) for chunk in result_chunks]\n",
    "        concurrent.futures.wait(futures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    " send_email('its me', f'done with {year} {quarter}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
